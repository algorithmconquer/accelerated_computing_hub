第 2 章：CUDA 简介
2006 年 11 月，NVIDIA® 推出了 CUDA®（Compute Unified Device Architecture，统一计算设备架构），这是一个通用的并行计算平台和编程模型。它利用 NVIDIA GPU 中的并行计算引擎，以比 CPU 更高效的方式解决许多复杂的计算问题。

如果 Python 开发人员正在使用高级库接口，则可以跳过本章。但如果您需要编写自己的内核函数，或需要将算法高效地映射到 GPU 架构中，这里介绍的概念将会派上用场。

CUDA 架构
在科学计算代码中，要在 GPU 上执行一个函数（又称“内核”，kernel），通常需要以下三个主要步骤：

将输入数据从 CPU 内存（主机内存）复制到 GPU 内存（设备内存）。
在 GPU 上加载并执行 GPU 内核。
将结果从 GPU 内存复制回 CPU 内存。
正如上一章所述，CPU 和 GPU 的架构不同，因此需要不同的编程范式。

CUDA 编程模型
CUDA 采用异构计算模型，涉及 CPU 和 GPU 协同工作。

内核 (Kernels)
CUDA 内核是在 GPU 上执行的全局函数。应用程序的并行部分由 K 个不同的 CUDA 线程并行执行 K 次，而不像 CPU 上的常规顺序函数那样只执行一次。

线程 (Threads) 和线程束 (Warps)
在 CUDA 中，内核通过线程来执行。线程是代表内核执行的一个抽象实体。它是 CUDA 中最小的执行单元，并拥有唯一的线程 ID（Thread ID）。

每 32 个连续线程组成一个“线程束”（warp）。线程束是流式多处理器（SM）中的基本执行单元。一旦一个线程块被分配给某个 SM，它将被进一步划分为一组线程束进行执行。每个线程块包含整数个线程束，GPU 上的操作是以线程束为单位执行的。

线程块 (Blocks)
一组线程被称为 CUDA 块（block）。同一块内的线程可以通过共享内存进行协作，并同步其内存访问与执行。CUDA 块被组织成网格（grid）。内核以“线程块网格”的形式执行。块数组执行相同的内核，将并行执行扩展到所有线程。

每个 CUDA 块由一个流式多处理器（SM）执行，且不能迁移到 GPU 中的其他 SM（除非在抢占、调试或 CUDA 动态并行期间）。根据 CUDA 块所需的资源，一个 SM 可以同时运行多个并发的 CUDA 块。每个内核在一个设备上执行，CUDA 支持在一个设备上同时运行多个内核。

GPU 内核执行



这些组件的分层结构不仅有助于管理线程执行，也反映了支持 CUDA 的 GPU 的物理架构。线程在多个流式多处理器（SM）上并发执行。

内存管理
理解 CUDA 内存层次结构对于优化 CUDA 程序的性能至关重要。GPU 具有多种内存，每种内存都有其特定的作用域和缓存。以有效利用共享内存的方式使用内存类型可以减少延迟并提高吞吐量。

主要类型包括：

全局内存 (Global memory)：所有线程均可访问。
共享内存 (Shared memory) / L1 缓存：同一块内的线程共享。
本地内存 (Local)：线程私有，但属于全局内存的一部分。
寄存器 (Registers)：线程私有。


还有其他一些需要注意的内存类型，但对于使用高级库构建加速 Python 应用程序来说，可能超出了讨论范围：

常量内存 (Constant memory)：所有线程均可访问的缓存只读内存。在 NVIDIA GPU 中，共享内存、L1 缓存和常量内存缓存都位于流式多处理器块内。因此，它们比 L2 缓存和 GPU RAM（显存）更快。
纹理内存 (Textures)：针对滤波、插值方法和所有线程随机访问而优化的只读内存。
内存类型会影响性能。例如，全局内存容量大但延迟可能较高；本地内存虽然是线程私有的，但因其属于全局内存的一部分，访问时间也可能较长；共享内存速度更快，但容量有限。

为了获得最佳性能，数据应驻留在最接近其处理位置且最匹配其访问模式的内存类型中。在可能的情况下，应将频繁访问或在线程间共享的数据移动到共享内存或存储在寄存器中。这将减少从全局内存提取数据的开销。

内存层次结构



该架构创建了一个托管内存池（managed memory pool），该池中的每一次分配都可以通过相同的地址或指针在主机（Host）和设备（Device）上访问。底层系统会将数据迁移到主机和设备。

在 GPU 加速应用中，实现最佳性能的关键在于能否在 CPU 和 GPU 之间高效地传输数据。CPU 和 GPU 之间的数据传输涉及通过 PCIe 总线移动数据，这可能会限制访问 CPU 和 GPU 本地内存的速度。

以 Python 化的方式前进
本章包含这些内存分配类型仅供参考，但在许多高级 CUDA Python 软件包中，内核执行、线程执行和内存管理的细节通常是隐藏的。大量生成的样板代码和智能默认值使得开发者无需调用低级 CUDA 功能即可编写高性能代码。不熟悉 C++ 的 Python 开发人员也会欣赏这些 API 的 Python 化（pythonic）特性。

普遍共识是：开发人员应针对其应用使用可用的最高级库，必要时再探索更低级的选项。大多数高级包都提供了低级功能的接口，因此如果高级库调用无法提供所需的性能，您仍可以选择使用低级功能。

资源
CUDA C++ 编程指南：https://docs.nvidia.com/cuda/cuda-c-programming-guide/

CUDA 工具包：https://developer.nvidia.com/cuda-toolkit

NVIDIA CUDA 开发者论坛：https://forums.developer.nvidia.com/c/accelerated-computing/cuda/206

